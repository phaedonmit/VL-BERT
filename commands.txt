python vcr/val.py \
  --a-cfg /experiments/faidon/VL-BERT/cfgs/vcr/base_q2a_4x16G_fp32.yaml \
  --r-cfg /experiments/faidon/VL-BERT/cfgs/vcr/base_qa2r_4x16G_fp32.yaml \
  --a-ckpt <checkpoint_of_q2a> 
  --r-ckpt <checkpoint_of_qa2r> \
  --gpus 0 \
  --result-path /experiments/faidon/results \
  --result-name vl-bert


  python vcr/val.py \
  --a-cfg /experiments/faidon/VL-BERT/cfgs/vcr/base_q2a_4x11G_fp32.yaml \
  --r-cfg /experiments/faidon/VL-BERT/cfgs/vcr/base_qa2r_4x11G_fp32.yaml \
  --gpus 0 \
  --result-path /experiments/faidon/results \
  --result-name vl-bert


--------------------------------------
train vcr

./scripts/nondist_run.sh vcr/train_end2end.py /experiments/faidon/VL-BERT/cfgs/vcr/base_q2a_4x16G_fp32.yaml /experiments/faidon/VL-BERT/checkpoints
./scripts/dist_run_single.sh 1 vcr/train_end2end.py /experiments/faidon/VL-BERT/cfgs/vcr/base_q2a_4x11G_fp32.yaml /experiments/faidon/VL-BERT/checkpoints
./scripts/dist_run_single.sh 1 vcr/train_end2end.py /experiments/faidon/VL-BERT/cfgs/vcr/base_qa2r_4x11G_fp32.yaml /experiments/faidon/VL-BERT/checkpoints

--------------------------------------
train vqa
./scripts/dist_run_single.sh 1 vqa/train_end2end.py /experiments/faidon/VL-BERT/cfgs/vqa/base_4x11G_fp32.yaml /experiments/faidon/VL-BERT/checkpoints

test vqa

python vqa/test.py \
  --cfg /experiments/faidon/VL-BERT/cfgs/vqa/base_4x11G_fp32.yaml \
  --ckpt /experiments/faidon/VL-BERT/checkpoints/output/vl-bert/vqa/base_4x11G_fp32/train2014+val2014_train/vl-bert_base_res101_vqa-best.model \
  --gpus 1 \
  --result-path /experiments/faidon/VL-BERT/results

--------------------------------------
pretrain multi30k
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 pretrain/train_end2end.py /experiments/faidon/VL-BERT/cfgs/flickr30k/base_e2e_16x16G_fp16.yaml /experiments/faidon/VL-BERT/checkpoints
pretrain multi30k_pretrained
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 pretrain/train_end2end.py /experiments/faidon/VL-BERT/cfgs/flickr30k/base_e2e_16x16G_fp16_pretrained.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=0 ./scripts/dist_run_single.sh 1 pretrain/train_end2end.py /experiments/faidon/VL-BERT/cfgs/flickr30k/base_e2e_16x16G_fp16_pretrained_german_corpus.yaml /experiments/faidon/VL-BERT/checkpoints

CUDA_VISIBLE_DEVICES=0 ./scripts/dist_run_single.sh 1 pretrain/train_end2end.py /experiments/faidon/VL-BERT/cfgs/flickr30k/base_prec_16x16G_fp16_pretrained.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 pretrain/train_end2end.py /experiments/faidon/VL-BERT/cfgs/flickr30k/base_prec_16x16G_fp16_pretrained_LR6.yaml /experiments/faidon/VL-BERT/checkpoints

pretrain CC
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 pretrain/train_end2end.py /experiments/faidon/VL-BERT/cfgs/pretrain/base_e2e_11x11G_fp16.yaml /experiments/faidon/VL-BERT/checkpoints
pretrain CC start from existing
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 pretrain/train_end2end.py /experiments/faidon/VL-BERT/cfgs/pretrain/base_e2e_11x11G_fp16_pretrained.yaml /experiments/faidon/VL-BERT/checkpoints

pretrain task B
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 pretrain/train_end2end.py /experiments/faidon/VL-BERT/cfgs/flickr30k/base_prec_16x16G_fp16_pretrained_LR6_taskB.yaml /experiments/faidon/VL-BERT/checkpoints


downstream image retrieval
CUDA_VISIBLE_DEVICES=0 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_e2e_16x16G_fp16_downstream_retrieval_LR_original.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=0 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_e2e_16x16G_fp16_downstream_retrieval_both_languages.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_e2e_16x16G_fp16_downstream_retrieval_german.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=2 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_e2e_16x16G_fp16_downstream_retrieval_english_LR6.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=0 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_e2e_16x16G_fp16_downstream_retrieval_english_LR6_40epochs.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_e2e_16x16G_fp16_downstream_retrieval_german_LR6_40epochs.yaml /experiments/faidon/VL-BERT/checkpoints

CUDA_VISIBLE_DEVICES=0 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_english_LR6_startLR6.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_german_LR6_startLR6.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=2 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_german_LR6_startEnglish5k.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_english_LR6.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=0 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_both_LR6.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_english_LR6_startLR6_CC_and_flickr.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_english_LR6_startLR6_monolingual_model.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_german_5x_LR6_startLR6.yaml /experiments/faidon/VL-BERT/checkpoints

CUDA_VISIBLE_DEVICES=2 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_mixed_5x_LR6_startLR6.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=2 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_mixed_5x_LR6_startTaskB.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_downstream_retrieval_english_LR6_startLR6_multi30k.yaml /experiments/faidon/VL-BERT/checkpoints


downstream translation retrieval
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_translate_vision.yaml /experiments/faidon/VL-BERT/checkpoints
no vision:
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 retrieval/train_end2end.py /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_translate_no_vision.yaml /experiments/faidon/VL-BERT/checkpoints

MLT
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 MLT/train_end2end.py /experiments/faidon/VL-BERT/cfgs/MLT/base_prec_16x16G_fp16_MLT_LR6_startLR6.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 MLT/train_end2end.py /experiments/faidon/VL-BERT/cfgs/MLT/base_prec_16x16G_fp16_MLT_LR6_startLR6_no_vision.yaml /experiments/faidon/VL-BERT/checkpoints
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 MLT/train_end2end.py /experiments/faidon/VL-BERT/cfgs/MLT/base_prec_16x16G_fp16_MLT_LR6_no_pretraining.yaml /experiments/faidon/VL-BERT/checkpoints


# for all tasks together:
CUDA_VISIBLE_DEVICES=3 ./scripts/dist_run_single.sh 1 pretrain/train_end2end.py /experiments/faidon/VL-BERT/cfgs/flickr30k/base_e2e_16x16G_fp16_fully_trained_itm.yaml /experiments/faidon/VL-BERT/checkpoints

-----------------------------------

image retrieval inference:

CUDA_VISIBLE_DEVICES=2 python retrieval/test.py \
  --cfg /experiments/faidon/VL-BERT/checkpoints/output/pretrain/itm_prec/004_prec_retrieval_german_LR6_startEnglish5k/train_train/base_prec_16x16G_fp16_downstream_retrieval_german_LR6_startEnglish5k.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/itm_prec/015_prec_retrieval_mixed_5x_startTaskB/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 015_prec_retrieval_mixed_5x_startTaskB_German

--------------------------------------

distance translation:

CUDA_VISIBLE_DEVICES=2 python retrieval/test.py \
  --cfg /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_translate_distance_no_vision.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/pretrain_prec/002_prec_LR1e6_multi30k/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 002_prec_LR1e6_multi30k_pooled_rep

CUDA_VISIBLE_DEVICES=2 python retrieval/test.py \
  --cfg /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_translate_distance_with_vision.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/pretrain_prec/002_prec_LR1e6_multi30k/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 002_prec_LR1e6_multi30k_cls_out_with_vision

--------------------------------------

MT classification

CUDA_VISIBLE_DEVICES=3 python retrieval/test.py \
  --cfg /experiments/faidon/VL-BERT/checkpoints/output/pretrain/translation_retrieval/001_prec_translation_retrieval_with_vision/train_train/base_prec_16x16G_fp16_translate_vision.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/translation_retrieval/001_prec_translation_retrieval_with_vision/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 001_prec_translation_retrieval_with_vision_19model

CUDA_VISIBLE_DEVICES=3 python retrieval/test.py \
  --cfg /experiments/faidon/VL-BERT/checkpoints/output/pretrain/translation_retrieval/002_prec_translation_retrieval_no_vision/train_train/base_prec_16x16G_fp16_translate_no_vision.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/translation_retrieval/002_prec_translation_retrieval_no_vision/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 002_prec_translation_retrieval_no_vision_19model

CUDA_VISIBLE_DEVICES=3 python retrieval/test.py \
  --cfg /experiments/faidon/VL-BERT/checkpoints/output/pretrain/translation_retrieval/002_prec_translation_retrieval_no_vision/train_train/base_prec_16x16G_fp16_translate_no_vision.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/translation_retrieval/002_prec_translation_retrieval_no_vision/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name dummy_classification

CUDA_VISIBLE_DEVICES=2 python retrieval/test.py \
  --cfg /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_translate_no_vision_IAPR.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/translation_retrieval/002_prec_translation_retrieval_no_vision/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 003_translation_retrieval_IAPR


CUDA_VISIBLE_DEVICES=1 python retrieval/test.py \
  --cfg /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_translate_no_Europarl.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/translation_retrieval/002_prec_translation_retrieval_no_vision/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name dummy_full_multi30k_new_no_vision

CUDA_VISIBLE_DEVICES=2 python retrieval/test.py \
  --cfg /experiments/faidon/VL-BERT/cfgs/retrieval/base_prec_16x16G_fp16_translate_with_vision_IAPR.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/translation_retrieval/001_prec_translation_retrieval_with_vision/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 005_translation_retrieval_IAPR_with_vision

------------------------------

MLT evaluation

CUDA_VISIBLE_DEVICES=3 python MLT/test.py \
  --cfg /experiments/faidon/VL-BERT/checkpoints/output/pretrain/MLT/001_MTL_ende_with_vision/train_train/base_prec_16x16G_fp16_MLT_LR6_startLR6.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/MLT/001_MTL_ende_with_vision/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 001_MTL_ende_with_vision

CUDA_VISIBLE_DEVICES=3 python MLT/test.py \
  --cfg /experiments/faidon/VL-BERT/checkpoints/output/pretrain/MLT/002_MLT_ende_no_vision/train_train/base_prec_16x16G_fp16_MLT_LR6_startLR6_no_vision.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/MLT/002_MLT_ende_no_vision/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 002_MLT_ende_no_vision

CUDA_VISIBLE_DEVICES=3 python MLT/test.py \
  --cfg /experiments/faidon/VL-BERT/checkpoints/output/pretrain/MLT/003_MLT_ende_with_vision_no_pretraining/train_train/base_prec_16x16G_fp16_MLT_LR6_no_pretraining.yaml \
  --ckpt  /experiments/faidon/VL-BERT/checkpoints/output/pretrain/MLT/003_MLT_ende_with_vision_no_pretraining/train_train/vl-bert_base_res101_pretrain_multitask-0019.model \
  --gpus 0 \
  --result-path /experiments/faidon/VL-BERT/checkpoints --result-name 003_MLT_ende_with_vision_no_pretraining


--------------------------------------
Tensorboard

ssh -L 16006:127.0.0.1:6006 fmitzalis@durga.doc.ic.ac.uk

tensorboard --logdir=/experiments/faidon/VL-BERT/checkpoints/output/pretrain/vl-bert/



-----------------------------------
Bottom up attention

docker run --gpus all -v /experiments/faidon/VL-BERT/data/flickr30:/workspace/images:ro -v /experiments/faidon/VL-BERT/data/flickr30/features:/workspace/features --rm -it airsplay/bottom-up-attention bash
docker run --gpus all -v /experiments/faidon/VL-BERT/data/conceptual-captions/val_image:/workspace/images:ro -v /experiments/faidon/VL-BERT/data/conceptual-captions/val_frcnn:/workspace/features --rm -it airsplay/bottom-up-attention bash

docker run --gpus all -v /experiments/faidon/VL-BERT/data/conceptual-captions/:/workspace/conceptual_captions --rm -it airsplay/bottom-up-attention bash

docker run --gpus all -v /experiments/faidon/VL-BERT/data/:/workspace/data --rm -it airsplay/bottom-up-attention bash

CUDA_VISIBLE_DEVICES=0 python extract_nlvr2_image.py --split train


python generate_tsv_v2.py --gpu 3 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/conceptual_captions/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split conceptual_captions_val --data_root /workspace/conceptual_captions  --out /workspace/conceptual_captions/val_frcnn/


python generate_tsv_v2.py --gpu 3 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/data/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split flickr30k_val --data_root /workspace/data  --out /workspace/data/flickr30k/val_frcnn/
python generate_tsv_v2.py --gpu 3 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/data/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split flickr30k_train --data_root /workspace/data  --out /workspace/data/flickr30k/train_frcnn/
python generate_tsv_v2.py --gpu 3 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/data/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split flickr30k_test --data_root /workspace/data  --out /workspace/data/flickr30k/test_frcnn/

python generate_tsv_v2.py --gpu 0 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/data/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split conceptual_captions_train --data_root /workspace/data/conceptual-captions  --out /workspace/data/conceptual-captions/train_frcnn/
python generate_tsv_v2.py --gpu 3 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/data/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split conceptual_captions_val --data_root /workspace/data/conceptual-captions  --out /workspace/data/conceptual-captions/val_frcnn/
python generate_tsv_v2.py --gpu 3 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/data/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split conceptual_captions_val --data_root /workspace/data/conceptual-captions  --out /workspace/data/conceptual-captions/val_frcnn/


python generate_tsv_v2.py --gpu 3 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/data/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split IAPR_val --data_root /workspace/data  --out /workspace/data/IAPR/val_frcnn/
python generate_tsv_v2.py --gpu 3 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/data/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split IAPR_train --data_root /workspace/data  --out /workspace/data/IAPR/train_frcnn/
python generate_tsv_v2.py --gpu 3 --cfg /opt/butd/experiments/cfgs/faster_rcnn_end2end_resnet.yml --def /opt/butd/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt --net /workspace/data/faster_rcnn_models/resnet101_faster_rcnn_final.caffemodel --split IAPR_test --data_root /workspace/data  --out /workspace/data/IAPR/test_frcnn/


------------------------------
Download gdrive 
source gdrive_download
gdrive_download [ID] [out_filename]








***********************
List of experiments:

multi30k 1st: events.out.tfevents.1591470332.durga








- with the image
text_input_ids shape:  torch.Size([16, 20])
text_token_type_ids shape:  torch.Size([16, 20])
text_visual_embeddings shape:  torch.Size([16, 20, 768])
text_mask shape:  torch.Size([16, 20])
object_vl_embeddings shape:  torch.Size([16, 21, 1536])
object_mask shape:  torch.Size([16, 21])
*** vl_embeddings.shape:  torch.Size([16, 42, 768])
*** object_vl_embeddings.shape:  torch.Size([16, 21, 768])
*** object_mask.shape:  torch.Size([16, 21])


- without new one
text_input_ids shape:  torch.Size([16, 49])
text_token_type_ids shape:  torch.Size([16, 49])
text_visual_embeddings shape:  torch.Size([16, 49, 768])
text_mask shape:  torch.Size([16, 49])
object_vl_embeddings shape:  torch.Size([16, 15, 1536])
object_mask shape:  torch.Size([16, 15])
*** vl_embeddings.shape:  torch.Size([16, 50, 768])
*** object_vl_embeddings.shape:  torch.Size([16, 15, 768])
*** object_mask.shape:  torch.Size([16, 15])